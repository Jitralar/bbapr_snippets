{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b8ece7",
   "metadata": {},
   "source": [
    "# Imputace chybějících hodnot (Missing Value Imputation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed2ea0",
   "metadata": {},
   "source": [
    "Chybějící hodnoty v datech mohou narušit analýzy a modely, proto je potřeba je vhodně doplnit (imputovat). Různé metody imputace nabízejí kompromis mezi jednoduchostí a přesností: od triviálních náhrad až po pokročilé modely využívající strojové učení. Volba metody závisí na povaze dat a důvodu, proč hodnoty chybí. Následuje přehled přístupů k imputaci chybějících hodnot:\n",
    "\n",
    "- Jednoduché náhrady – Nahrazení chybějících hodnot konstantou nebo jednoduchou statistikou (např. nulou, průměrem, mediánem či módní hodnotou). Tyto metody jsou rychlé a snadno pochopitelné, ale mohou zkreslit rozdělení dat.\n",
    "\n",
    "- Podobnostní metody – Imputace na základě podobných záznamů, například pomocí k-nejbližších sousedů (kNN) nebo shlukování. Chybějící hodnota se odhadne z hodnot záznamů, které jsou podle zvolené metriky vzdálenosti nejbližší neúplnému záznamu (případně se použije hodnota centroidu shluku).\n",
    "\n",
    "- Prediktivní modely – Využití tradičních algoritmů strojového učení k predikci chybějící hodnoty z ostatních atributů. Lze použít rozhodovací stromy, náhodné lesy (např. MissForest algoritmus) či další regresní modely. Tyto modely se učí vztahům v datech a mohou přesněji odhadnout chybějící položky.\n",
    "\n",
    "- Bayesovské přístupy – Statistické metody jako EM algoritmus (Expectation-Maximization) nebo vícenásobná imputace v řetězci (MICE) vytvářejí model distribučního rozdělení dat a opakovaně odhadují chybějící hodnoty na základě podmíněných rozdělení. Vícenásobná imputace generuje několik verzí doplněných datasetů, aby zohlednila nejistotu v odhadu.\n",
    "\n",
    "- Hluboké učení – Moderní přístupy využívají hluboké neuronové sítě k imputaci. Autoenkodéry dokáží zakódovat záznam do latentního prostoru a následně rekonstruovat i chybějící hodnoty. Generativní modely jako VAE (variační autoenkodér) nebo GAN (generativní adversariální sítě, např. GAIN) se trénují tak, aby doplňovaly chybějící položky realisticky – např. GAN přístup s generátorem a diskriminátorem iterativně zlepšuje kvalitu imputací."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13888c7",
   "metadata": {},
   "source": [
    "### ReMasker (Transformer MAE)\n",
    "ReMasker je moderní algoritmus založený na principu maskovaného autoenkodéru s architekturou Transformer​. Hlavní myšlenkou je „remasking“, kdy se během trénování kromě skutečně chybějících hodnot náhodně zneviditelní i část pozorovaných hodnot. Model (maskovací autoenkodér) se optimalizuje k rekonstrukci těchto uměle zamlžených hodnot a následně se využije k predikci původně chybějících položek​​. Transformerová síť se samoorganizovanou pozorností tak dokáže zachytit složité vztahy mezi atributy v tabulce​. ReMasker nevyžaduje silné předpoklady o mechanismu chybění a funguje i při velmi vysokém podílu chybějících dat (autoři uvádějí úspěšné imputace i při 70 % chybějících hodnot)​. V rozsáhlém benchmarku na 12 datových sadách dosahuje ReMasker obdobné nebo lepší přesnosti než 13 známých metod, přičemž s rostoucím podílem chybějících dat se jeho náskok ještě zvyšuje​. \n",
    "\n",
    "[ReMasker repozitář](https://github.com/tydusky/remasker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571ff7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Remasker example\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# This example shows how to use Remasker to create a mask for a given image.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_args_parser\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Remasker example\n",
    "# This example shows how to use Remasker to create a mask for a given image.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import get_args_parser\n",
    "from remasker_impute import ReMasker\n",
    "\n",
    "X_raw = np.arange(50).reshape(10, 5) * 1.0\n",
    "X = pd.DataFrame(X_raw, columns=['0', '1', '2', '3', '4'])\n",
    "X.iat[3,0] = np.nan\n",
    "\n",
    "imputer = ReMasker()\n",
    "\n",
    "imputed = imputer.fit_transform(X)\n",
    "print(imputed[3,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4515d8",
   "metadata": {},
   "source": [
    "### DeepIFSA \n",
    "\n",
    "DeepIFSA (Deep Imputation with Feature and Sample Attention) je framework, který využívá mechanismy pozornosti (attention) k imputaci tabulárních dat​. Model se učí samo-attention mezi vstupními rysy (sloupci) i mezi vzorky (řádky), čímž zachycuje vztahy jak mezi různými atributy, tak mezi různými záznamy. Inovativně je použit i trik z kontrastního učení – CutMix augmentace, kdy se části dat míchají, aby se zvýšila robustnost modelu​. DeepIFSA tak v podstatě kombinuje pozornost po sloupcích i řádcích v jedné hluboké síti. Podle výsledků autorů překonává tento přístup devět state-of-the-art metod v imputaci při různých typech chybění (MCAR, MAR, MNAR) a podílech chybějících dat 10–50 %​. Například ve zdravotnických EHR datech snížila pozornostní imputace normalizovanou RMSE o ~52–82 % oproti rozhodovacím stromečkům a dalším metodám​. Kód DeepIFSA je ve fázi výzkumného prototypu (autoři avizovali uvolnění na GitHubu)​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c8890",
   "metadata": {},
   "source": [
    "### DiffPuter\n",
    "\n",
    "DiffPuter představuje nejmodernější přístup využívající difuzní modely (známé z generování obrázků) pro imputaci tabulárních dat​​. Jde o kombinaci generativního difuzního modelu s EM algoritmem: model iterativně střídá fázi trénování (M-step), kdy se pomocí difuzního modelu odhaduje společné rozdělení dat včetně chybějících hodnot, a fázi vzorkování (E-step), kdy se chybějící hodnoty aktualizují podmíněným generováním z trénovaného modelu​. Tato kombinace umožňuje postupně zpřesňovat imputace i při vysoké nejistotě. Teoreticky autoři ukazují, že trénovací krok maximalizuje věrohodnost pozorovaných dat a vzorkovací krok odpovídá Bayesovskému odhadu chybějících hodnot​. V testech na 10 různorodých datových souborech DiffPuter překonal 17 existujících metod – průměrně o 8,1 % menší MAE a o 5,6 % menší RMSE než nejlepší porovnávaný algoritmus​. DiffPuter byl publikován jako ICLR 2025 Spotlight; autoři plánují vydat open-source kód (při publikaci na ICLR bývá uvolnění kódu běžné)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e099e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
